<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">
<head>
    <title>2. PEFT and Spring AI Implementation</title>
    <style type="text/css" media="screen">
		@import url( ../shared/style.css );
	</style>
	<script src="../shared/scormfunctions.js" type="text/javascript"></script>
	<script src="../shared/contentfunctions.js" type="text/javascript"></script>
</head>
<body>
<h1>2. PEFT and Spring AI Implementation</h1>

<p>Training full models is expensive and requires massive compute. In modern AI development, we use <strong>Parameter-Efficient Fine-Tuning (PEFT)</strong> to achieve similar results with a fraction of the resources.</p>

<h3>LoRA: Low-Rank Adaptation</h3>
<p>LoRA is the most popular PEFT technique. Instead of updating all billions of parameters in a model, LoRA freezes the original weights and adds small, trainable &quot;adapter&quot; layers. This reduces the number of trainable parameters by 10,000x and the GPU memory requirements by 3x, making it possible to fine-tune models on consumer hardware.</p>

<h3>Implementing Fine-Tuned Models in Spring AI</h3>
<p>Once you have a fine-tuned model (hosted on OpenAI, Azure, or locally via Ollama), Spring AI makes it easy to use. You simply need to specify the model ID of your fine-tuned version.</p>

<p><strong>Example: Using a Fine-Tuned OpenAI Model</strong></p>
<pre>
@RestController
public class FineTunedChatController {

    private final ChatClient chatClient;

    public FineTunedChatController(ChatClient.Builder builder) {
        // You can set the default model in the builder
        this.chatClient = builder
            .defaultOptions(OpenAiChatOptions.builder()
                .withModel(&quot;ft:gpt-3.5-turbo-0125:my-org:custom-model-id&quot;)
                .withTemperature(0.3f)
                .build())
            .build();
    }

    @GetMapping(&quot;/generate&quot;)
    public String generate(@RequestParam String prompt) {
        return chatClient.prompt()
                .user(prompt)
                .call()
                .content();
    }
}
</pre>

<p>By using the <code>chatClient</code>, your application code remains the same regardless of whether you are using a base model or a custom fine-tuned one, allowing for easy A/B testing and model swapping.</p>

<script type="text/javascript">
</script>
</body>
</html>