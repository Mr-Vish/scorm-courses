test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.m1_q1",
                                "What is the primary purpose of Data quality over quantity: Phi-3 achieves its performance through carefully curated \"text?",
                                QUESTION_TYPE_CHOICE,
                                new Array("No internet required", "Fine-Tuning Small Models with LoRA", "Data quality over quantity: Phi-3 achieves its performance through carefully curated \"text", "Ollama, llama.cpp"),
                                "Data quality over quantity: Phi-3 achieves its performance through carefully curated \"text",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.m1_q2",
                                "In the context of Small Models, what does Knowledge distillation: Smaller models can be trained on outputs from larger models, inher refer to?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Knowledge distillation: Smaller models can be trained on outputs from larger models, inher", "GPU delegate for speed", "~4M trainable params", "Latency-critical"),
                                "Knowledge distillation: Smaller models can be trained on outputs from larger models, inher",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.m1_q3",
                                "Which statement about Architecture improvements: Grouped-query attention, efficient tokenizers, and better train is accurate?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Architecture improvements: Grouped-query attention, efficient tokenizers, and better train", "Versatile edge model", "WebLLM, Transformers.js", "When Small Models Beat Large Models"),
                                "Architecture improvements: Grouped-query attention, efficient tokenizers, and better train",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.m1_q4",
                                "Which of the following best describes Task-specific training: Small models fine-tuned on specific domains can beat general-purpo?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Runs entirely on-device", "Autocomplete, real-time chat", "Ultra-lightweight for embedded", "Task-specific training: Small models fine-tuned on specific domains can beat general-purpo"),
                                "Task-specific training: Small models fine-tuned on specific domains can beat general-purpo",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.m1_q5",
                                "What is a key characteristic of Start small: Try a 3-7B model first - you may not need a 70B model for your use case?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Ollama, MLX, llama.cpp", "Start small: Try a 3-7B model first - you may not need a 70B model for your use case", "Multi-GPU, 80+ GB VRAM", "Single GPU, 8 GB VRAM"),
                                "Start small: Try a 3-7B model first - you may not need a 70B model for your use case",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.m1_q6",
                                "Which of the following is true regarding Fine-tune for your domain: A fine-tuned 3B model often beats a general-purpose 70B model o?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Reasoning on par with larger models due to curated training data", "Quick Start with Phi-3", "Approaches GPT-3.5 performance", "Fine-tune for your domain: A fine-tuned 3B model often beats a general-purpose 70B model o"),
                                "Fine-tune for your domain: A fine-tuned 3B model often beats a general-purpose 70B model o",
                                "obj_module_1")
                );