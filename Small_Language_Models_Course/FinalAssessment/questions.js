// Final Comprehensive Assessment
// Covers all 1 modules


test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.final_q1",
                                "Regarding Small Models: What is a key characteristic of LoRA is essential: Full fine-tuning is rarely needed - LoRA achieves 90-95% of the quality?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Apple MLX for Local Inference", "LoRA is essential: Full fine-tuning is rarely needed - LoRA achieves 90-95% of the quality", "WebLLM, Transformers.js", "Quantize for deployment: Always quantize (Q4_K_M) before deploying to edge devices"),
                                "LoRA is essential: Full fine-tuning is rarely needed - LoRA achieves 90-95% of the quality",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.final_q2",
                                "Regarding Small Models: In the context of Small Models, what does Quantize for deployment: Always quantize (Q4_K_M) before deploying to edge devices refer to?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Quantize for deployment: Always quantize (Q4_K_M) before deploying to edge devices", "TensorFlow Lite, MediaPipe", "Ollama, MLX, llama.cpp", "Medical triage, legal classification"),
                                "Quantize for deployment: Always quantize (Q4_K_M) before deploying to edge devices",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.final_q3",
                                "Regarding Small Models: What is the primary purpose of Benchmark on your data: Generic benchmarks do not predict performance on your specific tas?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Benchmark on your data: Generic benchmarks do not predict performance on your specific tas", "CUDA or CPU inference", "Personal assistants, health apps", "Fine-Tuning Small Models with LoRA"),
                                "Benchmark on your data: Generic benchmarks do not predict performance on your specific tas",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.com.scorm.genaicourse.smalllms.final_q4",
                                "Regarding Small Models: How is Reasoning on par with larger models due to curated training data best defined in this context?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Personal assistants, health apps", "Start small: Try a 3-7B model first - you may not need a 70B model for your use case", "Single GPU, 16 GB VRAM", "Reasoning on par with larger models due to curated training data"),
                                "Reasoning on par with larger models due to curated training data",
                                "obj_final_assessment")
                );