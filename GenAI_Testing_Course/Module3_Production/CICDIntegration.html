<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">
<head>
    <title>CI/CD Integration</title>
    <style type="text/css" media="screen">
		@import url( ../shared/style.css );
	</style>
	<script src="../shared/scormfunctions.js" type="text/javascript"></script>
	<script src="../shared/contentfunctions.js" type="text/javascript"></script>
</head>
<body>
<h1>CI/CD Integration</h1>

<h2>Testing in CI/CD Pipelines</h2>
<p>Integrate GenAI tests into your continuous integration and deployment workflows.</p>

<h2>Pipeline Stages</h2>
<table>
    <tr><th>Stage</th><th>Tests</th><th>Duration</th></tr>
    <tr><td class="rowheader">Pre-commit</td><td>Unit tests, linting</td><td>&lt; 1 min</td></tr>
    <tr><td class="rowheader">PR Validation</td><td>Integration tests, smoke tests</td><td>&lt; 5 min</td></tr>
    <tr><td class="rowheader">Nightly</td><td>Full evaluation suite</td><td>30-60 min</td></tr>
    <tr><td class="rowheader">Pre-release</td><td>Safety tests, benchmarks</td><td>1-2 hours</td></tr>
</table>

<h2>GitHub Actions Example</h2>
<div class="code-block">
<pre><code>name: GenAI Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run unit tests
        run: pytest tests/unit -v
      
      - name: Run integration tests (mocked)
        run: pytest tests/integration -v
        env:
          USE_MOCK_LLM: true
      
      - name: Run evaluation tests
        if: github.event_name == 'pull_request'
        run: python scripts/run_evaluations.py --sample 10
</code></pre>
</div>

<h2>Cost Management in CI/CD</h2>
<ul>
    <li>Use mocked responses for most tests</li>
    <li>Run expensive evaluations only on main branch</li>
    <li>Sample test cases (10% on PR, 100% nightly)</li>
    <li>Cache LLM responses between runs</li>
    <li>Set budget limits and alerts</li>
</ul>

<h2>Quality Gates</h2>
<div class="code-block">
<pre><code>def check_quality_gates(evaluation_results):
    gates = {
        "accuracy": 0.95,
        "relevance": 0.90,
        "hallucination_rate": 0.05,
        "latency_p95": 3.0
    }
    
    for metric, threshold in gates.items():
        actual = evaluation_results[metric]
        
        if metric == "hallucination_rate":
            if actual > threshold:
                raise QualityGateFailure(f"{metric}: {actual} > {threshold}")
        else:
            if actual < threshold:
                raise QualityGateFailure(f"{metric}: {actual} < {threshold}")
    
    print("All quality gates passed!")
</code></pre>
</div>

<script type="text/javascript">
</script>
</body>
</html>