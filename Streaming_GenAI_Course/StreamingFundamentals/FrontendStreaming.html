<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">
<head>
    <title>Frontend Streaming Implementation</title>
    <style type="text/css" media="screen">
        @import url( ../shared/style.css );
    </style>
    <script src="../shared/scormfunctions.js" type="text/javascript"></script>
    <script src="../shared/contentfunctions.js" type="text/javascript"></script>
</head>
<body>

<h1>Frontend Streaming Implementation</h1>

<h2>Why Frontend Streaming Matters</h2>
<p>
Streaming is only effective if the frontend is designed to consume and render partial
responses efficiently. A poorly implemented frontend can negate the benefits of backend
streaming by blocking rendering, reflowing excessively, or mishandling partial data.
</p>

<p>
A good streaming frontend:
</p>

<ul>
    <li>Displays content incrementally</li>
    <li>Feels responsive even for long outputs</li>
    <li>Handles interruptions gracefully</li>
    <li>Never freezes the UI thread</li>
</ul>

<h2>Browser Streaming Primitives</h2>
<p>
Modern browsers expose low-level streaming primitives through the Fetch API and the Streams
API. These APIs allow developers to process network responses chunk by chunk rather than
waiting for the full payload.
</p>

<p>
Key building blocks:
</p>

<ul>
    <li><code>fetch()</code> with streamed responses</li>
    <li><code>ReadableStream</code></li>
    <li><code>ReadableStreamDefaultReader</code></li>
    <li><code>TextDecoder</code></li>
</ul>

<h2>JavaScript SSE Client</h2>
<p>
The most common frontend approach for LLM streaming is to use a standard HTTP request that
returns an SSE-compatible response.
</p>

<div class="code-block">
<pre><code>
async function streamChat(message) {
    const response = await fetch('/chat/stream', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({ message })
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split('\n');

        for (const line of lines) {
            if (line.startsWith('data: ')) {
                const data = line.slice(6);

                if (data === '[DONE]') {
                    return;
                }

                const { text } = JSON.parse(data);
                appendToChat(text);  // Update UI incrementally
            }
        }
    }
}
</code></pre>
</div>

<h2>Understanding the Streaming Loop</h2>
<p>
This loop continuously reads from the response stream until completion. Each chunk may contain
partial tokens, multiple tokens, or partial lines.
</p>

<p>
Important considerations:
</p>

<ul>
    <li>Chunks are not aligned to tokens</li>
    <li>UTF-8 characters may span chunks</li>
    <li>Multiple SSE events may arrive together</li>
</ul>

<p>
Using <code>TextDecoder</code> with streaming enabled ensures text is decoded correctly across
chunk boundaries.
</p>

<h2>Incremental Rendering Strategy</h2>
<p>
Appending text token-by-token can be expensive if each update triggers layout reflow. Efficient
rendering strategies are essential.
</p>

<p>
Recommended techniques:
</p>

<ul>
    <li>Batch DOM updates when possible</li>
    <li>Append text nodes instead of replacing innerHTML</li>
    <li>Throttle rendering for very high token rates</li>
</ul>

<h2>React Streaming Pattern</h2>
<p>
In React applications, streaming must be integrated carefully to avoid excessive re-renders.
</p>

<ul>
    <li>Use <code>useState</code> to store accumulated text</li>
    <li>Append tokens rather than replacing the entire string</li>
    <li>Use <code>useRef</code> for scroll containers</li>
    <li>Show a typing indicator while streaming</li>
</ul>

<h2>Example React State Flow</h2>
<p>
A common pattern is:
</p>

<ul>
    <li>Initialize message state as empty</li>
    <li>Append streamed text to state</li>
    <li>Trigger auto-scroll after each append</li>
    <li>Finalize message on <code>[DONE]</code></li>
</ul>

<p>
Avoid storing each token as a separate React component — this leads to performance issues.
</p>

<h2>Auto-Scrolling Behavior</h2>
<p>
Auto-scrolling improves usability but must respect user intent.
</p>

<p>
Best practices:
</p>

<ul>
    <li>Auto-scroll only if the user is already near the bottom</li>
    <li>Pause auto-scroll if the user scrolls up</li>
    <li>Resume when the user scrolls back down</li>
</ul>

<h2>Typing Indicators and UX Signals</h2>
<p>
Streaming alone is not enough. Users benefit from explicit signals that generation is ongoing.
</p>

<ul>
    <li>Animated typing dots</li>
    <li>Cursor caret at the end of the text</li>
    <li>“Assistant is typing…” labels</li>
</ul>

<p>
These cues reduce uncertainty during pauses between tokens.
</p>

<h2>Error Handling</h2>
<p>
Streaming introduces failure modes that differ from traditional requests.
</p>

<ul>
    <li>
        <strong>Connection drops:</strong>
        Implement retry logic or allow users to regenerate.
    </li>
    <li>
        <strong>Timeouts:</strong>
        Use client-side timeouts (30–60 seconds) and surface clear messages.
    </li>
    <li>
        <strong>Partial responses:</strong>
        Always preserve and display what was already received.
    </li>
</ul>

<h2>Graceful Degradation</h2>
<p>
Not all environments support streaming equally well. Systems should degrade gracefully.
</p>

<ul>
    <li>Fallback to non-streamed responses if streaming fails</li>
    <li>Detect unsupported browsers</li>
    <li>Provide retry and refresh options</li>
</ul>

<h2>Cancellation and AbortController</h2>
<p>
Users often want to stop generation once they have enough information.
</p>

<p>
Frontend cancellation can be implemented using <code>AbortController</code>.
</p>

<ul>
    <li>Abort the fetch request</li>
    <li>Stop reading from the stream</li>
    <li>Update UI state immediately</li>
</ul>

<p>
Supporting cancellation improves perceived performance and reduces backend cost.
</p>

<h2>Accessibility Considerations</h2>
<p>
Streaming content must remain accessible.
</p>

<ul>
    <li>Use ARIA live regions sparingly</li>
    <li>Avoid screen reader overload</li>
    <li>Announce completion events clearly</li>
</ul>

<p>
Screen readers may read each incremental update, so batching updates can improve accessibility.
</p>

<h2>Performance Considerations</h2>
<p>
High-frequency updates can stress the main thread.
</p>

<ul>
    <li>Throttle rendering if token rate is high</li>
    <li>Avoid heavy syntax highlighting during streaming</li>
    <li>Apply formatting after completion</li>
</ul>

<h2>Security Considerations</h2>
<p>
Streamed content should be treated as untrusted until fully rendered.
</p>

<ul>
    <li>Escape HTML content</li>
    <li>Avoid direct innerHTML injection</li>
    <li>Delay code execution until completion</li>
</ul>

<h2>Testing Streaming Frontends</h2>
<p>
Testing streaming behavior requires more than snapshot tests.
</p>

<ul>
    <li>Simulate partial chunk delivery</li>
    <li>Test cancellation mid-stream</li>
    <li>Verify UI remains responsive</li>
</ul>

<h2>Best Practices Summary</h2>
<ul>
    <li>Process streams incrementally and safely</li>
    <li>Optimize rendering to avoid reflow storms</li>
    <li>Support cancellation and retries</li>
    <li>Preserve partial output on failure</li>
    <li>Design UX explicitly for streaming</li>
</ul>

<h2>Further Reading</h2>
<ul>
    <li>
        <a href="https://developer.mozilla.org/en-US/docs/Web/API/Streams_API" target="_blank">
        MDN – Streams API
        </a>
    </li>
    <li>
        <a href="https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream" target="_blank">
        MDN – ReadableStream
        </a>
    </li>
    <li>
        <a href="https://react.dev/learn" target="_blank">
        React Documentation – State and Effects
        </a>
    </li>
    <li>
        <a href="https://platform.openai.com/docs/guides/streaming" target="_blank">
        OpenAI – Streaming Guide
        </a>
    </li>
    <li>
        <a href="https://web.dev/streams/" target="_blank">
        web.dev – Streaming and Performance
        </a>
    </li>
</ul>

<script type="text/javascript">
</script>

</body>
</html>
