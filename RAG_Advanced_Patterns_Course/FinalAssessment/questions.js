// Final Assessment - Advanced RAG Patterns

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q1",
                                "Which search technique combines keyword and vector search for better results?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Semantic Search", "Hybrid Search", "Brute Force Search", "Recursive Search"),
                                "Hybrid Search",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q2",
                                "What is the primary role of Reciprocal Rank Fusion (RRF)?",
                                QUESTION_TYPE_CHOICE,
                                new Array("To encrypt search queries", "To merge and rank search results from different retrieval methods", "To summarize documents", "To calculate vector embeddings"),
                                "To merge and rank search results from different retrieval methods",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q3",
                                "Why are 'Cross-Encoders' used in reranking steps?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Because they are very fast", "Because they can capture deeper semantic relationships by processing the query and document together", "Because they use less memory than bi-encoders", "Because they are only compatible with SQL"),
                                "Because they can capture deeper semantic relationships by processing the query and document together",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q4",
                                "Which pattern involves rewriting a query into multiple variations to improve recall?",
                                QUESTION_TYPE_CHOICE,
                                new Array("HyDE", "Multi-Query Expansion", "Self-Reflection", "Contextual Compression"),
                                "Multi-Query Expansion",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q5",
                                "How does HyDE improve retrieval quality?",
                                QUESTION_TYPE_CHOICE,
                                new Array("By searching with a hypothetical answer generated by an LLM", "By deleting the user's query", "By using only metadata for search", "By increasing the temperature of the model"),
                                "By searching with a hypothetical answer generated by an LLM",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q6",
                                "Which pattern uses Community Detection and community summaries to answer 'global' questions?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Vector RAG", "GraphRAG", "Agentic RAG", "Recursive RAG"),
                                "GraphRAG",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q7",
                                "What is the primary benefit of Contextual Compression?",
                                QUESTION_TYPE_CHOICE,
                                new Array("It increases the context window size", "It removes irrelevant 'noise' from retrieved documents before passing them to the final model", "It makes the model more creative", "It translates documents in real-time"),
                                "It removes irrelevant 'noise' from retrieved documents before passing them to the final model",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q8",
                                "In the RAGAS framework, what does 'Context Precision' measure?",
                                QUESTION_TYPE_CHOICE,
                                new Array("The speed of the database", "The relevance of the retrieved documents to the query", "The grammar of the generated answer", "The total token usage"),
                                "The relevance of the retrieved documents to the query",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q9",
                                "What is the 'RAG Triad' in evaluation?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Search, Summarize, Synthesize", "Faithfulness, Answer Relevance, and Context Precision", "HNSW, IVF, and Flat Indexing", "GPT-4, Claude 3, and Llama 3"),
                                "Faithfulness, Answer Relevance, and Context Precision",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q10",
                                "Which RAG pattern uses a 'ReAct' loop to iteratively search and reason until a goal is met?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Linear RAG", "Agentic RAG", "GraphRAG", "Static RAG"),
                                "Agentic RAG",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q11",
                                "How does 'Long-Context RAG' differ from traditional small-chunk RAG?",
                                QUESTION_TYPE_CHOICE,
                                new Array("It uses more chunks of text", "It retrieves much larger, more complete sections of documents (e.g., chapters) to provide better nuance", "It only works with 4-bit models", "It removes all XML tags"),
                                "It retrieves much larger, more complete sections of documents (e.g., chapters) to provide better nuance",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q12",
                                "What is the primary trade-off when using HNSW indexing for vector stores?",
                                QUESTION_TYPE_CHOICE,
                                new Array("High speed vs. high memory usage", "Low accuracy vs. low cost", "Slow search vs. small index size", "No trade-offs; HNSW is always best"),
                                "High speed vs. high memory usage",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q13",
                                "Which model architecture is commonly used for mapping both text and images into the same vector space for Multimodal RAG?",
                                QUESTION_TYPE_CHOICE,
                                new Array("BERT", "CLIP", "ResNet", "GPT-2"),
                                "CLIP",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q14",
                                "What is the 'Lost in the Middle' phenomenon?",
                                QUESTION_TYPE_CHOICE,
                                new Array("When the database loses a document", "When LLM performance degrades when relevant information is in the middle of a very long prompt", "When an agent gets stuck in an infinite loop", "When a user forgets their password"),
                                "When LLM performance degrades when relevant information is in the middle of a very long prompt",
                                "obj_final_assessment")
                );

test.AddQuestion( new Question ("com.scorm.rag.advanced.final_q15",
                                "Why is 'Self-Querying' effective for datasets with structured metadata?",
                                QUESTION_TYPE_CHOICE,
                                new Array("It replaces the vector database with SQL", "It uses an LLM to turn natural language into precise metadata filters", "It makes the model more emotional", "It is only useful for personal journals"),
                                "It uses an LLM to turn natural language into precise metadata filters",
                                "obj_final_assessment")
                );