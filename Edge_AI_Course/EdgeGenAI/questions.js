test.AddQuestion( new Question ("q1",
                                "What distinguishes Optimization Checklist for Edge Deployment from other approaches?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Quantize aggressively: Use INT4 (Q4_K_M) for most edge devices - the quality tradeoff i...", "Qwen 0.5B, TinyLlama 1.1B", "Batch when possible: Even small batches (2-4) can significantly improve throughput", "Intermittent or offline"),
                                "Quantize aggressively: Use INT4 (Q4_K_M) for most edge devices - the quality tradeoff i...",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("q2",
                                "Which statement about Optimization Checklist for Edge Deployment is accurate?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Smartphone (mid-range): 4-6 GB", "Profile before optimizing: Measure actual bottlenecks (memory, compute, I/O) before mak...", "Smartphone (mid-range)", "Smartphone (high-end): 6-12 GB"),
                                "Profile before optimizing: Measure actual bottlenecks (memory, compute, I/O) before mak...",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("q3",
                                "What is the primary purpose of Optimization Checklist for Edge Deployment?",
                                QUESTION_TYPE_CHOICE,
                                new Array("ONNX for Cross-Platform Deployment", "Modern web browsers", "Full GPU capability for edge", "Use hardware-specific runtimes: Core ML on Apple, TensorRT on NVIDIA, QNN on Qualcomm"),
                                "Use hardware-specific runtimes: Core ML on Apple, TensorRT on NVIDIA, QNN on Qualcomm",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("q4",
                                "What role does Optimization Checklist for Edge Deployment play in this context?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Minimize model loading time: Use memory-mapped model files (mmap) for faster startup", "Connectivity", "Model Compression Techniques", "Android phones (Snapdragon)"),
                                "Minimize model loading time: Use memory-mapped model files (mmap) for faster startup",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("q5",
                                "Which of the following is true regarding Optimization Checklist for Edge Deployment?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Intermittent or offline", "4-6 GB", "Batch when possible: Even small batches (2-4) can significantly improve throughput", "Web browser"),
                                "Batch when possible: Even small batches (2-4) can significantly improve throughput",
                                "obj_module_1")
                );

test.AddQuestion( new Question ("q6",
                                "Which of the following best describes Optimization Checklist for Edge Deployment?",
                                QUESTION_TYPE_CHOICE,
                                new Array("WebLLM, Transformers.js", "Monitor thermal throttling: Edge devices may slow down under sustained AI workloads due...", "Edge Deployment Challenges", "WebGPU for Browser-Based AI"),
                                "Monitor thermal throttling: Edge devices may slow down under sustained AI workloads due...",
                                "obj_module_1")
                );