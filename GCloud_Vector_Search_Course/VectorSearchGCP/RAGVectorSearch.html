<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">
<head>
    <title>Building RAG with Vector Search</title>
    <style type="text/css" media="screen">
		@import url( ../shared/style.css );
	</style>
	<script src="../shared/scormfunctions.js" type="text/javascript"></script>
	<script src="../shared/contentfunctions.js" type="text/javascript"></script>
</head>
<body>
<h1>Building RAG with Vector Search</h1>


<h2>RAG Pipeline with Vertex AI Vector Search</h2>
<div class="code-block">
<pre><code>from vertexai.language_models import TextEmbeddingModel
from google.cloud import aiplatform

# Generate query embedding
embedding_model = TextEmbeddingModel.from_pretrained("text-embedding-004")
query_embedding = embedding_model.get_embeddings(["How to configure load balancing?"])[0].values

# Search the index
endpoint = aiplatform.MatchingEngineIndexEndpoint("projects/.../indexEndpoints/...")
results = endpoint.find_neighbors(
    deployed_index_id="docs_index_v1",
    queries=[query_embedding],
    num_neighbors=5
)

# Use results as context for Gemini
context_chunks = [fetch_document(r.id) for r in results[0]]</code></pre>
</div>

<h2>Hybrid Search Strategy</h2>
<p>Combine vector search with metadata filtering for precise results:</p>
<div class="code-block">
<pre><code># Filtered vector search
results = endpoint.find_neighbors(
    deployed_index_id="docs_index_v1",
    queries=[query_embedding],
    num_neighbors=10,
    filter=[
        aiplatform.matching_engine.matching_engine_index_endpoint.Namespace(
            name="category", allow_tokens=["networking", "security"]
        ),
        aiplatform.matching_engine.matching_engine_index_endpoint.NumericNamespace(
            name="last_updated", value_int=20240101, op="GREATER_EQUAL"
        )
    ]
)</code></pre>
</div>

<h2>Index Update Strategies</h2>
<table>
    <tr><th>Strategy</th><th>Use Case</th><th>Latency</th></tr>
    <tr><td>Batch update</td><td>Periodic full re-index</td><td>Minutes to hours</td></tr>
    <tr><td>Streaming update</td><td>Near real-time additions</td><td>Seconds</td></tr>
    <tr><td>Upsert</td><td>Update existing vectors</td><td>Seconds</td></tr>
    <tr><td>Remove</td><td>Delete vectors by ID</td><td>Seconds</td></tr>
</table>

<h2>Cost Optimization</h2>
<ul>
    <li>Use auto-scaling to reduce replicas during low-traffic periods</li>
    <li>Choose the smallest machine type that meets latency requirements</li>
    <li>Reduce embedding dimensions when possible (768 vs 1536)</li>
    <li>Use batch queries to amortize overhead across multiple searches</li>
    <li>Consider Vertex AI Search for managed RAG if you don't need custom indexing</li>
</ul>


<script type="text/javascript">
</script>
</body>
</html>