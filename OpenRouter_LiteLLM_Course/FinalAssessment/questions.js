test.AddQuestion( new Question ("q1",
                                "How does OpenRouter help developers manage costs when using multiple LLM providers?",
                                QUESTION_TYPE_CHOICE,
                                new Array("It automatically reduces the quality of the model to save money", "It hosts models for free", "It allows for easy comparison of prices across models and provides a unified billing system", "It gives away free credits to everyone"),
                                "It allows for easy comparison of prices across models and provides a unified billing system",
                                "obj_module_1")
                );
test.AddQuestion( new Question ("q2",
                                "What is a 'Fallback' strategy in LiteLLM?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Falling back to older version of Python", "A way to slow down the API calls", "Deleting the application if it crashes", "Automatically trying a secondary model or provider if the primary one fails"),
                                "Automatically trying a secondary model or provider if the primary one fails",
                                "obj_module_1")
                );
test.AddQuestion( new Question ("q3",
                                "Which of these is a key feature of LiteLLM's Router?",
                                QUESTION_TYPE_CHOICE,
                                new Array("Load balancing across multiple deployments of the same model", "Building a website", "Playing music", "Increasing the internet speed"),
                                "Load balancing across multiple deployments of the same model",
                                "obj_module_1")
                );
