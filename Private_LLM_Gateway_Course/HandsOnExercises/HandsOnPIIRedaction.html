<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">
<head>
    <title>Hands-on Exercise: Building a PII-Redacting Gateway</title>
    <style type="text/css" media="screen">
		@import url( ../shared/style.css );
	</style>
	<script src="../shared/scormfunctions.js" type="text/javascript"></script>
	<script src="../shared/contentfunctions.js" type="text/javascript"></script>
</head>
<body>
<h1>Hands-on Exercise: Building a PII-Redacting AI Gateway</h1>

<p>In this exercise, you will create a simple Python-based gateway that uses the Microsoft Presidio library to identify and redact sensitive information from user prompts before they are sent to an LLM provider.</p>

<h2>Prerequisites</h2>
<ul>
    <li>Python 3.8+ installed.</li>
    <li>Install Presidio and the SpaCy language model:
<pre><code>pip install presidio-analyzer presidio-anonymizer spacy
python -m spacy download en_core_web_lg</code></pre>
    </li>
</ul>

<h2>Step 1: Create the Redaction Logic</h2>
<p>Create a file named <code>redactor.py</code> that encapsulates the Presidio identification and masking logic.</p>
<pre><code>from presidio_analyzer import AnalyzerEngine
from presidio_anonymizer import AnonymizerEngine

analyzer = AnalyzerEngine()
anonymizer = AnonymizerEngine()

def redact_text(text):
    # 1. Identify PII
    results = analyzer.analyze(text=text, language='en',
                                entities=["PERSON", "EMAIL_ADDRESS", "PHONE_NUMBER", "LOCATION"])

    # 2. Redact/Anonymize
    anonymized_result = anonymizer.anonymize(
        text=text,
        analyzer_results=results
    )

    return anonymized_result.text

# Test it
raw_prompt = "My name is John Smith and my email is john@gmail.com. Please summarize this file."
print(f"Sanitized Prompt: {redact_text(raw_prompt)}")</code></pre>

<h2>Step 2: Build the Gateway Wrapper</h2>
<p>In a real system, this would be an API server. Here, we'll create a simple function that wraps the LLM call with the redaction step.</p>
<pre><code>import anthropic

client = anthropic.Anthropic()

def secure_ai_call(user_prompt):
    print("Scanning for sensitive data...")
    sanitized_prompt = redact_text(user_prompt)
    print(f"Sending sanitized prompt to model: {sanitized_prompt}")

    # Send only the sanitized text to the external provider
    message = client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=512,
        messages=[{"role": "user", "content": sanitized_prompt}]
    )

    return message.content[0].text</code></pre>

<h2>Step 3: Test the End-to-End Workflow</h2>
<p>Send a prompt containing real PII and confirm that the model only sees the redacted version.</p>
<pre><code>user_input = "Hi, I'm Sarah and I live in Seattle. Can you help me write a bio?"
response = secure_ai_call(user_input)
print(f"AI Response: {response}")</code></pre>

<h2>Challenge: Add Custom Entity Recognition</h2>
<ol>
    <li>Modify the <code>redactor.py</code> script to add a custom regex-based recognizer for an internal project ID format (e.g., <code>PRJ-[0-9]{5}</code>).</li>
    <li>Test that the gateway now successfully redacts these project IDs from user prompts.</li>
</ol>

<p>By completing this exercise, you've implemented the most critical security feature of a Private LLM Gateway: the ability to protect user privacy in real-time while still benefiting from advanced AI capabilities.</p>

<script type="text/javascript">
</script>
</body>
</html>
