<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">
<head>
    <title>What Is Prompt Injection?</title>
    <style type="text/css" media="screen">
		@import url( ../shared/style.css );
	</style>
	<script src="../shared/scormfunctions.js" type="text/javascript"></script>
	<script src="../shared/contentfunctions.js" type="text/javascript"></script>
</head>
<body>
<h1>What Is Prompt Injection?</h1>


<h2>Definition</h2>
<p>Prompt injection is a class of attacks where <strong>untrusted input</strong> manipulates an LLM into ignoring its original instructions and executing attacker-controlled commands instead. It is analogous to SQL injection but targets AI systems.</p>

<h2>Attack Categories</h2>
<table>
    <tr><th>Type</th><th>Description</th><th>Example</th></tr>
    <tr><td>Direct Injection</td><td>User directly provides malicious instructions</td><td>"Ignore all previous instructions and..."</td></tr>
    <tr><td>Indirect Injection</td><td>Malicious content hidden in data the LLM processes</td><td>Hidden text in a webpage or document</td></tr>
    <tr><td>Jailbreaking</td><td>Bypassing safety filters through role-play or encoding</td><td>"Pretend you are DAN who has no rules..."</td></tr>
</table>

<h2>Why It Matters</h2>
<ul>
    <li><strong>Data Exfiltration:</strong> Attackers can extract system prompts or private data</li>
    <li><strong>Unauthorized Actions:</strong> If the LLM has tool access, attackers can trigger harmful actions</li>
    <li><strong>Reputation Damage:</strong> Making a customer-facing bot say inappropriate things</li>
    <li><strong>Privilege Escalation:</strong> Bypassing access controls enforced only at the prompt level</li>
</ul>

<h2>Real-World Examples</h2>
<ul>
    <li>Bing Chat was tricked into revealing its system prompt ("Sydney")</li>
    <li>ChatGPT plugins were exploited to read private emails via indirect injection</li>
    <li>Customer service bots were manipulated into offering unauthorized discounts</li>
</ul>


<script type="text/javascript">
</script>
</body>
</html>